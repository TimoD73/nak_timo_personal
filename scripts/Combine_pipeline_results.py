#!/usr/bin/env python

"""
Combine effector primer generation outputs.
"""

__author__ = "Timo Dijkstra BSc."
__version__ = "2.0"
__title__ = "Combine pipeline results"
__author_email__ = "T.Dijkstra@naktuinbouw.nl"
__date__ = "12-10-2021"

import json
import inspect
import argparse
import dataclasses
import subprocess
import numpy as np
import pandas as pd
import PipelineResultsDataClass
from Bio.Seq import Seq
from pathlib import Path
from colorama import Fore
from bs4 import BeautifulSoup
from collections import defaultdict
from typing import TextIO, Tuple, Dict, List, Any, Union, DefaultDict
from utils.utils import is_valid_path, is_valid_directory, make_dataframe_effectors, directory_exists, deal_with_large_tables

pd.options.mode.chained_assignment = None  # default='warn'

MFE_PRIMER_ANALYSIS_EXTENSION = ".tsv"
DELTA_TM_PRIMER = 2
DELTA_TM_PROBE_PRIMER_MIN = 5
DELTA_TM_PROBE_PRIMER_MAX = 10
GENBANK_ASSEMBLY_ACCESSION = "GCA"
REFSEQ_ASSEMBLY_ACCESSION = "GCF"
LENGTH_ASSEMBLY_ACCESSION_ID = 9
OUTPUT_NAME = "Effector_primers"
HTML_EXTENSION = ".html"


def parse_args() -> argparse:
    """ Parse command line arguments """
    parser = argparse.ArgumentParser(description="Script to combine results from T3SEpp, Primer3, and MFEprimer.")
    parser.add_argument("-t", "--t3sepp", required=False, type=str, default="",
                        help=".out.txt file generated by run_T3SEpp.py")
    parser.add_argument("-p", "--primer3", required=True, type=argparse.FileType("r"),
                        help=".tsv file generated by Primer_design_script.py")
    parser.add_argument("-mi", "--mfe_ingroup", required=True, type=lambda x: is_valid_directory(parser, x),
                        help="The directory storing .tsv files generated by Analyze_MFEprimer_output.py "
                             "for the ingroup genomes (including the target genome). Make sure no other .tsv files"
                             "are stored in this directory.")
    parser.add_argument("-mo", "--mfe_outgroup", required=True, type=str,
                        help="The directory storing .tsv files generated by Analyze_MFEprimer_output.py "
                             "for the outgroup genomes. Make sure no other .tsv files are stored in this directory.")
    parser.add_argument("-o", "--output", required=False, default=Path("./"), type=Path,
                        help="Relative path of output directory.")
    parser.add_argument("-ms", "--multiplex_script", required=True, type=lambda x: is_valid_path(parser, x),
                        help="Path to Search_for_multiplex_assay_combinations.py")
    parser.add_argument('-l', '--labels', type=Path, required=False, default="",
                        help='Path to the Labels.json file generated by mash_dendrogram.py giving annotations by '
                             'the distances.')

    args = parser.parse_args()
    return args


def load_dataframe(file: Union[TextIO, Path]) -> pd.DataFrame:
    """
    Load a dataframe from an opened file.
    :param file: An opened file.
    :return: A Pandas dataframe.
    """
    dataframe = pd.read_csv(file, sep="\t")
    return dataframe


def generate_primer3_dataframe(primer3_file: TextIO) -> pd.DataFrame:
    """
    Format the Primer3 results using a dataframe. Insert an additional column as key to join dataframes later on.
    Since the order of the primer analysis has been the same for Primer3 output and MFEprimer output,
    is is allowed to insert this key column for joining tables.
    :param primer3_file: An opened .tsv file generated by Primer_design_script.py
    :return: A Primer3 results dataframe without instances that have no primers.
    """
    primer3_df = load_dataframe(primer3_file)
    primer3_df.insert(0, "Primer set", list(range(1, 1 + primer3_df.shape[0])), True)
    primer3_df = primer3_df.rename(columns={"Fasta header": "prot"})
    primer3_df["prot"] = [str(id).split()[0] for id in list(primer3_df["prot"])]
    return primer3_df.dropna()


def open_mfe_tsv_files(list_files: List[Path]) -> pd.DataFrame:
    """
    Check if there is at least one file in the directory and return a dataframe, otherwise quit.
    :param list_files: A list with all .tsv files in the given directory.
    :return: If at least one file is present in the directory,
    return a (concatenated) dataframe storing all MFEprimer data constructed from every .tsv file.
    """
    if len(list_files) >= 1:
        return merge_mfe_dataframes(list_files)
    else:
        print(F"{Fore.RED}No .tsv files in {list_files}.")
        quit()


def format_mfe_df(tsv_file: Path) -> pd.DataFrame:
    """
    Format the MFEprimer results using a dataframe. Split the Identifier column for a key to join dataframes later on.
    :param tsv_file: An opened .tsv file generated by Analyze_MFEprimer_output.py.
    :return: A Pandas dataframe.
    """
    df = load_dataframe(tsv_file)
    df.rename(columns={"Unnamed: 0": "Identifier"}, inplace=True)
    df[["Primer set", "Identifier"]] = df.Identifier.str.split("_", 1, expand=True, )
    return df


def merge_mfe_dataframes(list_files: List[Path]) -> pd.DataFrame:
    """
    Concatenate MFEprimer dataframes. If there is only one file. Return this dataframe.
    Otherwise, continue concatenating.
    :param list_files: A list with all .tsv files in the given directory.
    :return: A (concatenated) dataframe storing all MFEprimer data constructed from every .tsv file.
    """
    list_dataframes = []
    suffixes = [str(suffix) for suffix in list(range(0, len(list_files) + 1))]

    for i in range(len(list_files)):
        list_dataframes.append(format_mfe_df(list_files[i]))
        if len(list_files) == 1:
            break
        if i >= 1:
            list_dataframes.append(pd.merge(list_dataframes[-2], list_dataframes[-1], on="Primer set", how="inner",
                                            suffixes=(suffixes[i], suffixes[i+1])))
    list_dataframes[-1]["Primer set"] = pd.to_numeric(list_dataframes[-1]["Primer set"])
    return list_dataframes[-1].sort_values(by=["Primer set"])


def change_mfe_column_names(df: pd.DataFrame, group: str) -> pd.DataFrame:
    """
    Change the columns in such a way that the program is able to traceback which column belongs to an ingroup and
    which column to an outgroup.
    :param df: A merged MFEprimer dataframe for either the ingroup or the outgroup containing all the tool results.
    :param group: A string that is either ingroup or outgroup.
    :return: The dataframe with adjusted column names.
    """
    adjusted_column_names = [group + "_" + col_name for col_name in list(df.columns)
                             if col_name != "Primer set"]
    primer_set_index = int(np.where([col_name == "Primer set" for col_name in list(df.columns)])[0])
    adjusted_column_names.insert(primer_set_index, "Primer set")
    df.columns = adjusted_column_names
    return df


def generate_mfe_dataframes(ingroup_path: Path, outgroup_path: Path) -> pd.DataFrame:
    """
    Find .tsv files for the ingroup and the outgroup in the given directories and return a merged dataframe from all
    these .tsv files. Make sure that the column contains an identifier for the ingroup and the outgroup.
    :param ingroup_path: The directory storing .tsv files generated by Analyze_MFEprimer_output.py
    for the ingroup genomes (including the target genome). Make sure no other .tsv files are stored in this directory.
    :param outgroup_path: The directory storing .tsv files generated by Analyze_MFEprimer_output.py
    for the outgroup genomes. Make sure no other .tsv files are stored in this directory.
    :return: A merged dataframe of all MFEprimer dataframes for the ingroup as well as the outgroup (if given).
    """
    ingroup_files = list(Path(ingroup_path).glob("*" + MFE_PRIMER_ANALYSIS_EXTENSION))
    ingroup_merged_dataframe = open_mfe_tsv_files(ingroup_files)
    ingroup_merged_dataframe = change_mfe_column_names(ingroup_merged_dataframe, "Ingroup")
    if outgroup_path:
        outgroup_files = list(Path(outgroup_path).glob("*" + MFE_PRIMER_ANALYSIS_EXTENSION))
        outgroup_merged_dataframe = open_mfe_tsv_files(outgroup_files)
        outgroup_merged_dataframe = change_mfe_column_names(outgroup_merged_dataframe, "Outgroup")
        return pd.merge(ingroup_merged_dataframe, outgroup_merged_dataframe, on="Primer set", how="inner")
    else:
        return ingroup_merged_dataframe


def combine_dataframes(primer3_df: pd.DataFrame, mfe_df: pd.DataFrame, t3sepp_df: pd.DataFrame = "") -> pd.DataFrame:
    """
    Make a master dataframe containing all results generated by the primer generation pipeline.
    In addition, remove duplicate rows.
    :param primer3_df: A Primer3 results dataframe without instances that have no primers.
    :param mfe_df: A merged dataframe of all MFEprimer dataframes.
    :param t3sepp_df: A dataframe computed from the run_T3SEpp.py output.
    :return: A merged dataframe.
    """
    combined_df = pd.merge(mfe_df, primer3_df, on="Primer set", how="inner")
    if isinstance(t3sepp_df, pd.DataFrame):
        combined_df = pd.merge(combined_df, t3sepp_df, on="prot", how="inner")
    return combined_df


def get_general_results(dataframe_row: pd.Series, columns: pd.Index) -> PipelineResultsDataClass.GeneralResults:
    """
    Get the GeneralResults object.
    :param dataframe_row: One row, depicting a primer set, from the master dataframe containing all pipeline results.
    :param columns: Lists all columns of the dataframe necessary to get results from multiple columns without
    having to know how many columns.
    :return: GeneralResults object.
    """
    general_results = PipelineResultsDataClass.GeneralResults(
        dataframe_row["prot"],
        dataframe_row["T3SEpp"] if "T3SEpp" in list(columns) else "NA",
        dataframe_row["PRIMER_LEFT_SEQUENCE"],
        dataframe_row["PRIMER_RIGHT_SEQUENCE"],
        dataframe_row["PRIMER_INTERNAL_SEQUENCE"],
        len(dataframe_row["PRIMER_LEFT_SEQUENCE"]),
        len(dataframe_row["PRIMER_RIGHT_SEQUENCE"]),
        len(dataframe_row["PRIMER_INTERNAL_SEQUENCE"]),
        dataframe_row["PRIMER_LEFT_GC_PERCENT"],
        dataframe_row["PRIMER_RIGHT_GC_PERCENT"],
        dataframe_row["PRIMER_INTERNAL_GC_PERCENT"],
        dataframe_row["PRIMER_PAIR_PRODUCT_SIZE"]
    )
    return general_results


def get_primer3_results(dataframe_row: pd.Series) -> PipelineResultsDataClass.Primer3:
    """
    Get the Primer3 object.
    :param dataframe_row: One row, depicting a primer set, from the master dataframe containing all pipeline results.
    :return: Primer3 object.
    """
    return PipelineResultsDataClass.Primer3(
        dataframe_row["PRIMER_LEFT_TM"],
        dataframe_row["PRIMER_RIGHT_TM"],
        dataframe_row["PRIMER_INTERNAL_TM"],
        dataframe_row["PRIMER_LEFT_SELF_ANY_TH"],
        dataframe_row["PRIMER_LEFT_SELF_ANY_TH"],
        dataframe_row["PRIMER_INTERNAL_SELF_ANY_TH"],
        dataframe_row["PRIMER_LEFT_SELF_END_TH"],
        dataframe_row["PRIMER_RIGHT_SELF_END_TH"],
        dataframe_row["PRIMER_INTERNAL_SELF_END_TH"],
        dataframe_row["PRIMER_LEFT_HAIRPIN_TH"],
        dataframe_row["PRIMER_RIGHT_HAIRPIN_TH"],
        dataframe_row["PRIMER_INTERNAL_HAIRPIN_TH"],
        dataframe_row["PRIMER_LEFT_END_STABILITY"],
        dataframe_row["PRIMER_RIGHT_END_STABILITY"],
        dataframe_row["PRIMER_PAIR_COMPL_ANY_TH"],
        dataframe_row["PRIMER_PAIR_COMPL_END_TH"]
    )


def get_column_name(columns: pd.Index, startswith: str) -> List[str]:
    """
    Since the merged dataframe has columns with similar names, differentiated by the last character, we need to
    extract the column that start with a particular string, ignoring the last character.
    :param columns: List with available columns.
    :param startswith: String characterizing the start of the column name.
    :return: The column name of interest.
    """
    return [col_name for col_name in columns if col_name.startswith(startswith)][0]


def check_result_availability(value: str) -> bool:
    """
    If no amplicon was produced, there will be no result. Check this.
    :param value: Result.
    :return: True if the result is not available.
    """
    if type(value) == str:
        return value == "nan"


def extract_number_of_amplicons_qpcr(dataframe_row: pd.Series, columns: pd.Index, group: str) -> List[int]:
    """
    Take the number of amplicons for every primer set.
    :param dataframe_row: One row, depicting a primer set, from the master dataframe containing all pipeline results.
    :param columns: Lists all columns of the dataframe necessary to get results from multiple columns without
    having to know how many columns.
    :param group: A string that is either <Ingroup> or <Outgroup>.
    :return: A list with the number of amplicons.
    """
    number_of_amplicons = []
    column_names = [col_name for col_name in columns if col_name.startswith(group + "_Number of amplicons qpcr")]
    for column_name in column_names:
        current_cell = dataframe_row[column_name]
        if check_result_availability(str(current_cell)):
            number_of_amplicons.append(0)
        else:
            number_of_amplicons.append(int(current_cell))
    return number_of_amplicons


def extract_length_of_amplicons_qpcr(dataframe_row: pd.Series, columns: pd.Index, group: str) -> \
        List[List[Union[int, str]]]:
    """
    Take the length(s) for the amplicons for every primer set and make a nested list. If no amplicons are produced,
    return ["NA"]. If only one amplicon is produced, append this single length, otherwise return a list.
    :param dataframe_row: One row, depicting a primer set, from the master dataframe containing all pipeline results.
    :param columns: Lists all columns of the dataframe necessary to get results from multiple columns without
    having to know how many columns.
    :param group: A string that is either <Ingroup> or <Outgroup>.
    :return: A nested list with lengths of each amplicon for every MFEprimer run.
    """
    lengths = []
    column_names = [col_name for col_name in columns if col_name.startswith(group + "_Length amplicons qpcr")]
    for column_name in column_names:
        current_cell = dataframe_row[column_name]
        if check_result_availability(str(current_cell)):
            lengths.append(["NA"])
        elif isinstance(current_cell, (np.integer, np.floating)):
            lengths.append([int(current_cell)])
        else:
            lengths.append(list(map(int, current_cell.split(","))))
    return lengths


def extract_delta_g_primer(dataframe_row: pd.Series, columns: pd.Index, group: str, primer: str) -> \
        List[List[Union[float, str]]]:
    """
    Take the delta G for a certain primer and make a nested list. If no amplicons are produced, return ["NA"].
    If only one amplicon is produced, append this single delta G.
    :param dataframe_row: One row, depicting a primer set, from the master dataframe containing all pipeline results.
    :param columns: Lists all columns of the dataframe necessary to get results from multiple columns without
    having to know how many columns.
    :param group: A string that is either <Ingroup> or <Outgroup>.
    :param primer: Either one of the following options [<forward primer>. <reverse primer>, <probe primer>].
    :return: A list with delta G of each amplicon for every MFEprimer run for a given primer.
    """
    delta_g = []
    column_names = [col_name for col_name in columns if col_name.startswith(group + "_Delta G " + primer)]
    for column_name in column_names:
        current_cell = dataframe_row[column_name]
        if type(current_cell) == str:
            delta_g_list = list(map(float, current_cell.split(",")))
            delta_g.append([round(dg, 2) for dg in delta_g_list])
        elif np.isnan(current_cell):
            delta_g.append(["NA"])
        elif isinstance(current_cell, np.floating):
            delta_g.append([round(float(current_cell), 2)])
    return delta_g


def get_mfeprimer_results(dataframe_row: pd.Series, columns: pd.Index) -> PipelineResultsDataClass.MfePrimer:
    """
    Get the MfePrimer object.
    :param dataframe_row: One row, depicting a primer set, from the master dataframe containing all pipeline results.
    :param columns: Lists all columns of the dataframe necessary to get results from multiple columns without
    having to know how many columns.
    :return: MfePrimer object.
    """
    return PipelineResultsDataClass.MfePrimer(
        dataframe_row[get_column_name(columns, "Ingroup_Left primer Tm")],
        dataframe_row[get_column_name(columns, "Ingroup_Right primer Tm")],
        dataframe_row[get_column_name(columns, "Ingroup_Probe primer Tm")],
        dataframe_row[get_column_name(columns, "Ingroup_No hairpin")],
        dataframe_row[get_column_name(columns, "Ingroup_No dimer")],
        dataframe_row[get_column_name(columns, "Ingroup_Control is specific")],
        dataframe_row[get_column_name(columns, "Outgroup_Control is specific")],
        [int(dataframe_row[column_name]) for column_name in
         [col_name for col_name in columns if col_name.startswith("Ingroup_Amplicons")]],
        extract_number_of_amplicons_qpcr(dataframe_row, columns, "Ingroup"),
        extract_length_of_amplicons_qpcr(dataframe_row, columns, "Ingroup"),
        [int(dataframe_row[column_name]) for column_name in
         [col_name for col_name in columns if col_name.startswith("Outgroup_Amplicons")]],
        extract_number_of_amplicons_qpcr(dataframe_row, columns, "Outgroup"),
        extract_length_of_amplicons_qpcr(dataframe_row, columns, "Outgroup"),
        extract_delta_g_primer(dataframe_row, columns, "Ingroup", "forward primer"),
        extract_delta_g_primer(dataframe_row, columns, "Ingroup", "reverse primer"),
        extract_delta_g_primer(dataframe_row, columns, "Ingroup", "probe primer"),
        extract_delta_g_primer(dataframe_row, columns, "Outgroup", "forward primer"),
        extract_delta_g_primer(dataframe_row, columns, "Outgroup", "reverse primer"),
        extract_delta_g_primer(dataframe_row, columns, "Outgroup", "probe primer")
    )


def get_genome_names(dataframe_row: pd.Series, columns: pd.Index) -> PipelineResultsDataClass.GenomeNames:
    """
    Get the genome names object.
    :param dataframe_row: One row, depicting a primer set, from the master dataframe containing all pipeline results.
    :param columns: Lists all columns of the dataframe necessary to get results from multiple columns without
    having to know how many columns.
    :return: genome names object.
    """
    return PipelineResultsDataClass.GenomeNames(
        [dataframe_row[column_name] for column_name in [
            col_name for col_name in columns if col_name.startswith("Ingroup_Genome name")]],
        [dataframe_row[column_name] for column_name in [
            col_name for col_name in columns if col_name.startswith("Outgroup_Genome name")]]
    )


def get_target_amplicon(dataframe_row: pd.Series, columns: pd.Index) -> Seq:
    """
    A function that assigns the target amplicon if all primers are present in the amplicon.
    It scans the amplplicons from short to long. Small amplicons might still be qPCR detectable but are a by-product
    and are not the desired target. In that case find the desired target.
    :param dataframe_row: One row, depicting a primer set, from the master dataframe containing all pipeline results.
    :param columns: Lists all columns of the dataframe necessary to get results from multiple columns without
    having to know how many columns.
    :return: The target amplicon for qPCR.
    """
    ingroup_amplicons = dataframe_row[get_column_name(columns, "Ingroup_Amplicon sequences qpcr")].split(",")
    forward = Seq(dataframe_row["PRIMER_LEFT_SEQUENCE"])
    reverse = Seq(dataframe_row["PRIMER_RIGHT_SEQUENCE"])
    probe = Seq(dataframe_row["PRIMER_INTERNAL_SEQUENCE"])
    for amplicon in ingroup_amplicons:
        if (str(forward) in amplicon or str(Seq.reverse_complement(forward)) in amplicon) and \
            (str(reverse) in amplicon or str(Seq.reverse_complement(reverse)) in amplicon) and \
                (str(probe) in amplicon or str(Seq.reverse_complement(probe)) in amplicon):
            return amplicon


def loop_over_amplicon_column_names(dataframe_row: pd.Series, column_names: List[str]):
    """
    Retrieve amplicon sequences from the specified columns.
    :param dataframe_row: One row, depicting a primer set, from the master dataframe containing all pipeline results.
    :param column_names: Lists columns of which the amplicon sequence needs to be extracted.
    :return: List of amplicon sequences. ["NA"] if no amplicon sequence is available.
    """
    amplicons = []
    for column_name in column_names:
        current_cell = dataframe_row[column_name]
        if check_result_availability(str(current_cell)):
            amplicons.append(["NA"])
        else:
            amplicons.append(str(current_cell).split(","))
    return amplicons


def get_amplicons(dataframe_row: pd.Series, columns: pd.Index) -> PipelineResultsDataClass.Amplicons:
    """
    Get the Amplicons object. Consider the first amplicon of the ingroup as the target. Do the same process for the
    regular amplicons and for the extended amplicons.
    :param dataframe_row: One row, depicting a primer set, from the master dataframe containing all pipeline results.
    :param columns: Lists all columns of the dataframe necessary to get results from multiple columns without
    having to know how many columns.
    :return: Amplicons object. The off targets are empty if not more than 2 amplicons are found by MFEprimer.
    """
    def extract_amplicons(dataframe_row: pd.Series, columns: pd.Index, extended: bool):
        extended_str = "Extended amplicon" if extended else "Amplicon"
        ingroup_amplicon_target_sequence = [str(dataframe_row[column_name]).split(",")[0] for column_name in
                                            [col_name for col_name in columns
                                             if col_name.startswith(f"Ingroup_{extended_str} sequences qpcr")]]
        ingroup_amplicon_target_sequence = "\n".join(list(map(lambda x: "NA" if x == "nan" else x,
                                                              ingroup_amplicon_target_sequence)))
        off_targets_ingroup = [amplicons[1:] if len(amplicons[1:]) != 0 else ["NA"] for amplicons in
                               loop_over_amplicon_column_names(dataframe_row, [col_name for col_name in columns if
                              col_name.startswith(f"Ingroup_{extended_str} sequences qpcr")])]
        amplicons_outgroup = loop_over_amplicon_column_names(dataframe_row, [col_name for col_name in columns if
                             col_name.startswith(f"Outgroup_{extended_str} sequences qpcr")])

        return ingroup_amplicon_target_sequence, off_targets_ingroup, amplicons_outgroup

    ingroup_amplicon_target_sequence, off_targets_ingroup, amplicons_outgroup = \
        extract_amplicons(dataframe_row, columns, False)

    ingroup_amplicon_target_sequence_extended, off_targets_ingroup_extended, amplicons_outgroup_extended = \
        extract_amplicons(dataframe_row, columns, True)

    return PipelineResultsDataClass.Amplicons(
        ingroup_amplicon_target_sequence,
        ingroup_amplicon_target_sequence_extended,
        off_targets_ingroup,
        off_targets_ingroup_extended,
        amplicons_outgroup,
        amplicons_outgroup_extended
    )


def check_tm(primer3: PipelineResultsDataClass.Primer3, mfeprimer: PipelineResultsDataClass.MfePrimer):
    """
    Execute methods for Primer3 and MFEprimer to check the Tm values.
    :param primer3: Primer3 object.
    :param mfeprimer: MfePrimer object.
    """
    primer3.check_tm_primers(DELTA_TM_PRIMER)
    primer3.check_tm_probe(DELTA_TM_PROBE_PRIMER_MIN, DELTA_TM_PROBE_PRIMER_MAX)

    mfeprimer.check_tm_primers(DELTA_TM_PRIMER)
    mfeprimer.check_tm_probe(DELTA_TM_PROBE_PRIMER_MIN, DELTA_TM_PROBE_PRIMER_MAX)


def initialize_classes(dataframe: pd.DataFrame) -> Tuple[Dict[str, dict], List[str]]:
    """
    Function that loops over all rows (primer sets) of the combined master dataframe. It takes the results and
    transforms them into an object. It checks the Tm values and makes one combined object, which is transformed to a
    dictionary. Finally, it saves the attributes of the combined object for later use.
    :param dataframe: A merged dataframe.
    :return dict_primerset_objects: Dictionary of results ordered by object.
    :return pipeline_results_attributes: Attributes of Pipeline_results_DataClass.PipelineResults.
    """
    dict_primerset_objects = {}
    pipeline_results_attributes = []
    for primerset in range(dataframe.shape[0]):
        general_results = get_general_results(dataframe.iloc[primerset], dataframe.columns)
        general_results.check_five_prime_probe()
        primer3_results = get_primer3_results(dataframe.iloc[primerset])
        mfeprimer_results = get_mfeprimer_results(dataframe.iloc[primerset], dataframe.columns)
        genome_names = get_genome_names(dataframe.iloc[primerset], dataframe.columns)
        amplicons = get_amplicons(dataframe.iloc[primerset], dataframe.columns)

        check_tm(primer3_results, mfeprimer_results)

        combined_results = PipelineResultsDataClass.PipelineResults(general_results, primer3_results,
                                                                      mfeprimer_results, genome_names, amplicons)

        combined_results.check_great_primers()
        combined_results.check_specific_with_control()

        dict_primerset_objects["primer set " + str(primerset + 1)] = dataclasses.asdict(combined_results)

        attributes = inspect.getmembers(combined_results, lambda a: not (inspect.isroutine(a)))
        pipeline_results_attributes = [a[0] for a in attributes if not (a[0].startswith('__') and a[0].endswith('__'))]

        print(f"{Fore.BLUE}Finshed processing results for primer set {primerset + 1}/{dataframe.shape[0]}.")

    return dict_primerset_objects, pipeline_results_attributes


def convert_to_default_dict(list_dictionaries: List[dict]) -> DefaultDict[str, list]:
    """
    Convert a dictionary for every primer set to a default dictionary for a specific attribute.
    :param list_dictionaries: Every element of the list is a primer storing all results.
    :return: A default dictionary with format merged_dict[<column>]. Each column stores all results.
    """
    merged_dict = defaultdict(list)
    for dictionary in list_dictionaries:
        for key, value in dictionary.items():
            merged_dict[key].append(value)
    return merged_dict


def merge_dictionaries(combined_results: Dict[str, dict], attributes: List[str]) -> Dict[str, DefaultDict[str, list]]:
    """
    Take the nested dictionaries listing all results for every primer set. Transform these results into four
    dictionaries. One for every attribute list (attributes from Pipeline_results_DataClass.PipelineResults).
    :param combined_results: Dictionary of results ordered by object.
    :param attributes: Attributes of Pipeline_results_DataClass.PipelineResults.
    :return: Nested dictionary. It contains a dictionary with results for every attribute (dataframe).
    Each nested dictionary will be a dataframe with each key representing a column.
    """
    merged_dictionaries = {}

    for attribute in attributes:
        merged_dictionaries[attribute] = convert_to_default_dict([combined_results[primer_set][attribute]
                                                                  for primer_set in combined_results])
    return merged_dictionaries


def provide_ncbi_assembly_hyperlink(genome_names: List[str], label_dict: Dict[str, str] = None) -> List[str]:
    """
    Loop over the column of the genome names table. Split by an underscore and if the name contains either "GCF" or
    "GCA" then we search for this accession type. We presume that the accession ID is the next element in the list.
    If the id is indeed a digit of length nine, we add hyperlink.
    :param genome_names: Column of the genome_names table.
    :param label_dict: Dictionary with GCF accessions as key and organism names as value.
    :return: The same column with hyperlinks where possible and the original column.
    """

    def find_accession(list_genome_name_elements: list, assembly_accession_type: str, hyperlink_str: str) -> str:
        try:
            assembly_accession_index = list_genome_name_elements.index(assembly_accession_type) + 1
            presumed_assembly_accession = genome_name[assembly_accession_index]
            if presumed_assembly_accession.isdigit() and len(presumed_assembly_accession) == LENGTH_ASSEMBLY_ACCESSION_ID:
                return F'<a href="https://www.ncbi.nlm.nih.gov/assembly/{assembly_accession_type}_' \
                       F'{presumed_assembly_accession}/" target="_blank">{hyperlink_str}</a>'
        except ValueError:
            return hyperlink_str
    genome_names_with_ncbi_hyperlink = []
    for index, genome_name in enumerate(genome_names):
        genome_name = genome_name.split("_")
        if label_dict is not None:
            keys_labels = list(label_dict.keys())
            matching_keys_labels = [genome_names[index] in label for label in keys_labels]
            matching_key_index = [index for index, x in enumerate(matching_keys_labels) if x]
            if len(matching_key_index) == 1:
                organism_name = label_dict.get(keys_labels[int(matching_key_index[0])])
                genome_names[index] = f"{organism_name} ({genome_names[index]})"
        if GENBANK_ASSEMBLY_ACCESSION in genome_name:
            genome_names_with_ncbi_hyperlink.append(
                find_accession(genome_name, GENBANK_ASSEMBLY_ACCESSION, genome_names[index]))
        elif REFSEQ_ASSEMBLY_ACCESSION in genome_name:
            genome_names_with_ncbi_hyperlink.append(
                find_accession(genome_name, REFSEQ_ASSEMBLY_ACCESSION, genome_names[index]))
        else:
            genome_names_with_ncbi_hyperlink.append(genome_names[index])
    return genome_names_with_ncbi_hyperlink


def reformat_genome_names_df(dataframe: pd.DataFrame, labels: Path) -> pd.DataFrame:
    """
    Make a dataframe for the genome names. Make sure that the column lengths are equal. If the genome name contains a
    GCF ID, provide a hyperlink to the NCBI assembly page.
    :param dataframe: The GenomeNames dataframe from the nested dictionary.
    :param labels: Path to the Labels.json file generated by mash_dendrogram.py giving annotations by the distances.
    :return: A reformated GenomeNames dataframe.
    """
    ingroup_genomes = sorted(dataframe.iloc[0]["Genome_names_ingroup"])
    outgroup_genomes = sorted(dataframe.iloc[0]["Genome_names_outgroup"])
    length_differ = max(len(ingroup_genomes), len(outgroup_genomes)) - min(len(ingroup_genomes), len(outgroup_genomes))
    if len(ingroup_genomes) < len(outgroup_genomes):
        ingroup_genomes += ["NA"] * length_differ
    elif len(ingroup_genomes) > len(outgroup_genomes):
        outgroup_genomes += ["NA"] * length_differ
    if labels.is_file():
        with open(labels) as js:
            label_dict = json.load(js)
        ingroup_genomes_hyperlinks = provide_ncbi_assembly_hyperlink(ingroup_genomes, label_dict)
        outgroup_genomes_hyperlinks = provide_ncbi_assembly_hyperlink(outgroup_genomes, label_dict)
    else:
        ingroup_genomes_hyperlinks = provide_ncbi_assembly_hyperlink(ingroup_genomes)
        outgroup_genomes_hyperlinks = provide_ncbi_assembly_hyperlink(outgroup_genomes)
    dataframe = pd.DataFrame(data={
        "ingroup_genomes_raw": ingroup_genomes,
        "outgroup_genomes_raw": outgroup_genomes,
        "ingroup_genomes": ingroup_genomes_hyperlinks,
        "outgroup_genomes": outgroup_genomes_hyperlinks
    })
    dataframe.index += 1
    return dataframe


def remove_duplicates(dataframe: pd.DataFrame, df_key: str) -> pd.DataFrame:
    """
    Remove duplicate rows based on specific keys for each dataframe and reset the index starting from 1.
    :param dataframe: One of the dataframes from the nested dictionary.
    :param df_key: The key of one of those nested dictionaries used for the title.
    :return: Dataframe with unique rows.
    """
    if df_key == "general_results":
        dataframe = dataframe.drop_duplicates(subset=["forward_primer_sequence", "reverse_primer_sequence",
                                                      "probe_sequence"])
    elif df_key == "mfe_primer":
        dataframe = dataframe.drop_duplicates(subset=["forward_tm", "reverse_tm", "probe_tm"])
    elif df_key == "primer3":
        dataframe = dataframe.drop_duplicates(subset=["forward_tm", "reverse_tm", "probe_tm"])
    elif df_key == "amplicons":
        dataframe = dataframe.drop_duplicates(subset=["amplicon_target_ingroup_extended"])
    dataframe.reset_index(drop=True, inplace=True)
    dataframe.index += 1
    return dataframe


def format_text(dataframe: pd.DataFrame, title: str) -> Tuple[pd.DataFrame, str]:
    """
    Capitalize the first letter and replace underscores for white spaces. Capitalize the "gc" In GC percentage.
    Capitalize PCR in qpcr.
    :param dataframe: One of the dataframes from the nested dictionary.
    :param title: The key of one of those nested dictionaries used for the title, also used as html table title.
    :return: The dataframe with reformatted column names and a reformatted title.
    """
    dataframe.columns = [column[0].upper() + column[1:].replace("_", " ") if not column.startswith("gc") else
                         column[0:2].upper() + column[2:].replace("_", " ") for column in list(dataframe.columns)]
    dataframe.columns = [column.replace("pcr", "PCR") for column in list(dataframe.columns)]
    dataframe.columns = [column.replace("Delta g", "ΔG") for column in list(dataframe.columns)]
    dataframe.columns = [column.replace("tm", "T<sub>m</sub>") for column in list(dataframe.columns)]
    title = title[0].upper() + title[1:].replace("_", " ") if title != "mfe_primer" else \
        title[0:3].upper() + title[3:].replace("_", "")
    return dataframe, title


def style_precision(df: pd.DataFrame, title: str) -> pd.DataFrame.style:
    """
    Adjust the precision of values and add unit symbols or 5' 3' identifiers to elements of the table.
    :param df: One of the dataframes from the nested dictionary.
    :param title: The key of one of those nested dictionaries used for the title.
    :return: Customized dataframe.
    """
    if title == "General results":
        return df.style.format(precision=0, formatter={
            "T3sepp prediction score": "{:}",
            "Forward primer sequence": "5' {:} 3'",
            "Reverse primer sequence": "5' {:} 3'",
            "Probe sequence": "5' {:} 3'",
            "GC forward primer": "{:.2f}%",
            "GC reverse primer": "{:.2f}%",
            "GC probe primer": "{:.2f}%",
            "Great primers ingroup": "{:.2f}%",
            "Great primers outgroup": "{:.2f}%"
        })
    elif title == "Primer3" or title == "MFEprimer":
        return df.style.format(precision=2, formatter={
            "Forward tm": "{:.2f}°C",
            "Reverse tm": "{:.2f}°C",
            "Probe tm": "{:.2f}°C"
        })
    else:
        return df.style.format(formatter={})


def format_caption(title) -> str:
    """
    Add captions to the corresponding tables.
    :param title: The key of one of those nested dictionaries used for the title.
    :return: String in html format to make a caption.
    """
    caption = ""
    if title == "General results":
        caption = f'{title}<br><span style="color:#a14115; font-size:20px">General statistics for the presented ' \
                  f'assays. The T3SEpp score refers to the likeliness score generated by the T3SEpp with 1.00 as ' \
                  f'maximum. The prediction whether there will be no dimers and no hairpins is assessed using ' \
                  f'MFEprimer. Finally, primers are defined great for the ingroup if there is only one qPCR ' \
                  f'detectable amplicon predicted by MFEprimer, while  primers are defined great for the outgroup if ' \
                  f'there are no qPCR detectable amplicons predicted by MFEprimer.</span>'
    elif title == "Primer3":
        caption = f'{title}<br><span style="color:#a14115; font-size:20px">Primer design statistics given by Primer3. '\
                  f'Good delta T<sub>m</sub> primers is assessed by checking whether there is not more than a 2 ' \
                  f'degree Celcius difference between the forward and reverse primer. Good delta T<sub>m</sub> probe ' \
                  f'primer is assessed by checking if the probe T<sub>m</sub> is within a given temperature range of ' \
                  f'5 to 10 degrees Celcius calculated from the lowest primer T<sub>m</sub>.</span>'
    elif title == "MFEprimer":
        caption = f'{title}<br><span style="color:#a14115; font-size:20px">Important MFEprimer statistics. Good delta '\
                  f'T<sub>m</sub> primers is assessed by checking whether there is not more than a 2 degree Celcius ' \
                  f'difference between the forward and reverse primer. Good delta T<sub>m</sub> probe primer is ' \
                  f'assessed by checking if the probe is within a given temperature range of 5 to 10 degrees Celcius ' \
                  f'calculated from the lowest primer T<sub>m</sub>. The ingroup and outgroup summaries brings you to ' \
                  f'a nested table with specific MFEprimer statistics per genome.</span>'
    elif title == "Multiplex":
        caption = f'{title}<br><span style="color:#a14115; font-size:20px">Table that shows which assays are ' \
                  f'predicted to work in multiplex. Here, we take only assays with a 100% ingroup specificity. We ' \
                  f'search for assays that only have zero or one off-target amplicons in all outgroup genomes. If so, '\
                  f'the "Promising multiplex combination" column will be True.</span>'
    elif title == "Amplicons":
        caption = f'{title}<br><span style="color:#a14115; font-size:20px">Table with summary information for ' \
                  f'predicted amplicons.</span>'
    elif title == "Genome names":
        caption = f'{title}<br><span style="color:#a14115; font-size:20px">Table to list all the genomes in ' \
                  f'alphabetical order.</span>'
    elif "Nested MFEprimer results" in title:
        caption = f'{title}<br><span style="color:#a14115; font-size:20px">Additional MFEprimer statistics for the ' \
                  f'given assay per genome. Number of amplicons refers to amplicons generated by solely the forward ' \
                  f'and reverse primer. Number of qPCR detectable amplicons means that besides the forward and ' \
                  f'reverse primer, MFEprimer predicts that the probe will also bind in between. ΔG refers to the ' \
                  f'free energy. The lower the free energy, the more easily the primer will bind.</span>'
    elif "Amplicons assay" in title and "ingroup" in title:
        caption = f'{title}<br><span style="color:#a14115; font-size:20px">Predicted amplicons by MFEprimer for the ' \
                  f'ingroup. The target is the amplicon of interest. The off targets are unwanted products. This ' \
                  f'column should ideally be empty.</span>'
    elif "Amplicons assay" in title and "outgroup" in title:
        caption = f'{title}<br><span style="color:#a14115; font-size:20px">Predicted amplicons by MFEprimer for ' \
                  f'the outgroup. The off targets are unwanted products. This column should ideally be empty.</span>'
    return caption


def color_bool(val: Any) -> str:
    """
    Find booleans in a dataframe and color them according to the value.
    :param val: One value from the dataframe.
    :return: The color of the text for that particular cell.
    """
    if type(val) == bool:
        color = 'darkgreen' if val else 'red'
        return 'color: %s' % color


def color_zeroes(val: Any) -> str:
    """
    Find booleans in a dataframe and color them green if they are 0.
    :param val: One value from the dataframe.
    :return: The color of the text for that particular cell.
    """
    if type(val) == float:
        color = 'darkgreen' if val == 0 else 'black'
        return 'color: %s' % color


def color_great_primers(val: float) -> str:
    """
    Color the great primers in the general results dataframe. 100% is green. >= 95% is orange. <95% is red.
    :param val: One value from the dataframe.
    :return: The color of the text for that particular cell.
    """
    if val == 100:
        color = 'darkgreen'
    elif val >= 95:
        color = '#ffa31a'
    else:
        color = 'red'
    return 'color: %s' % color


def format_df(df: pd.DataFrame, title: str) -> pd.DataFrame.style:
    """
    Customize the .html tables.
    :param df: One of the dataframes from the nested dictionary.
    :param title: The key of one of those nested dictionaries used for the title.
    :return: Customized dataframe and .html output.
    """
    s = style_precision(df, title)

    cell_hover = {  # for row hover use <tr> instead of <td>
        'selector': 'td:hover',
        'props': [('background-color', '#cbb600')]
    }
    index_names = {
        'selector': '.index_name',
        'props': 'font-style: italic; color: darkgrey; font-weight:normal;'
    }
    headers = {
        'selector': 'th:not(.index_name)',
        'props': 'background-color: #a14115; color: #cbb600;'
    }
    caption = {
        'selector': 'caption',
        'props': [
            ('color', '#cbb600'),
            ('font-size', '40px'),
            ("text-align", "left")]
    }
    border = {"border": "1.3px solid #a14115"}

    s.set_table_styles([cell_hover, index_names, headers, caption])
    s.set_properties(**border)
    caption = format_caption(title)
    s.set_caption(caption)
    if title == "Primer3":
        s.applymap(color_bool)
        s.applymap(color_zeroes)
    elif title == "General results":
        s.applymap(color_bool)
        s.applymap(color_great_primers, subset=["Great primers ingroup", "Great primers outgroup"])
    else:
        s.applymap(color_bool)
    return s


def make_output_path(output: Path, df_name: str) -> Tuple[Path, Path]:
    """
    Make a unique path for every output dataframe.
    :param output: Relative path of output directory.
    :param df_name: Name of the dataframe.
    :return: Output path for a dataframe in the format: <path>/<user defined name>_<dataframe name>.tsv/.html.
    """
    df_file_path = output / "_".join([OUTPUT_NAME, df_name])
    return df_file_path.with_suffix(".tsv"), df_file_path.with_suffix(".html")


def make_nested_dataframes(df: pd.DataFrame, genome_names_series: pd.Series, group: str, df_type: str,
                               output: Path) -> Tuple[pd.DataFrame, Dict[str, pd.DataFrame], Dict[str, Path],
                                                      Dict[str, Path]]:
    """
    Function to generate nested dataframes for the given results where every result per genome is shown in a new
    dataframe.
    :param df: Dataframe that needs to be transformed to a nested dataframe with hyperlinks.
    :param genome_names_series: The extracted column with genome names from the genome_names dataframe
    for the corresponding group.
    :param group: Either <ingroup> or <outgroup>.
    :param df_type: Either <mfeprimer> or <amplicon> to specify the dataframe.
    :param output: Relative path of output directory.
    :return: The input dataframe, a dictionary with dataframes for the chosen group,
    a dictionary with output .tsv paths, and a dictionary with output .html paths
    """
    nested_dataframes = {}
    output_paths_tsv = {}
    output_paths_html = {}
    summary_column = []
    columns_subset = [column for column in list(df.columns) if group in column]
    subset = df[columns_subset]
    filename = "Nested_MFEprimer_results_assay" if df_type == "mfeprimer" else "Amplicons_assay"
    # Remove NAs from the genome names
    genome_names_series.drop(genome_names_series.index[genome_names_series == "NA"], inplace=True)
    for index, assay in subset.iterrows():
        nested_dict = {}
        tsv_output, html_output = make_output_path(output, F"{filename}_{str(index)}_{group}")
        output_paths_tsv[F"{filename}_{str(index)}_{group}"] = tsv_output
        output_paths_html[F"{filename}_{str(index)}_{group}"] = html_output
        summary_column.append(F'<a href="{html_output.name}">Summary</a>')
        for item, value in assay.items():
            nested_dict["genome_names"] = genome_names_series
            # Convert nested lists to strings separated by comma.
            if df_type == "mfeprimer":
                nested_dict[item] = [", ".join([str(x) for x in sublist]) if type(sublist) == list
                                     else sublist for sublist in value]
            else:
                # Make a column for the off-targets amplicons
                nested_column = ["\n".join([str(x) for x in sublist]) for sublist in value if type(sublist) == list]
                # Make a column for the target amplicons
                nested_dict[item] = nested_column if len(nested_column) > 0 else value.split("\n")
        dataframe = pd.DataFrame.from_dict(nested_dict)
        dataframe.sort_values(by=["genome_names"], inplace=True)
        nested_dataframes[F"{filename}_{str(index)}_{group}"] = dataframe
    df[group + "_summary_column"] = summary_column
    df.drop(columns=columns_subset, inplace=True)
    return df, nested_dataframes, output_paths_tsv, output_paths_html


def write_main_dataframes_to_output_files(dataframe_dict: Dict[str, pd.DataFrame], output: Path) -> Dict[str, Path]:
    """
    Write the main dataframes (general results, primer3, MFEprimer, amplicons, genome names) to an output file in the
    formats .tsv and .html. Save for the genome names a .tsv file without hyperlinks.
    :param dataframe_dict: Dictionary that contains the main dataframes.
    :param output: Relative path of output directory.
    :return: Dictionary with the .html paths for the main dataframes.
    """
    output_path_html_files = {}
    for key in dataframe_dict:
        tsv_output, html_output = make_output_path(output, key)
        output_path_html_files[key] = html_output
        dataframe, title = format_text(dataframe_dict[key], key)
        if key == "genome_names":
            dataframe_raw = dataframe[[column for column in dataframe.columns if column.endswith("raw")]]
            dataframe = dataframe[[column for column in dataframe.columns if not column.endswith("raw")]]
            with open(tsv_output, "w") as tsv:
                # noinspection PyTypeChecker
                dataframe_raw.to_csv(tsv, sep="\t")
        else:
            with open(tsv_output, "w") as tsv:
                # noinspection PyTypeChecker
                dataframe.to_csv(tsv, sep="\t")

        formatted_df = format_df(dataframe, title)
        with open(html_output, "w") as html:
            html.write(formatted_df.to_html())
    return output_path_html_files


def write_nested_dataframes_to_output(dataframe_dict, tsv_out_dict: Dict[str, Path], html_out_dict: Dict[str, Path]):
    """
    Write the nested dataframes to an output file in the formats .tsv and .html.
    :param dataframe_dict: Dictionary that contains the nested dataframes.
    :param tsv_out_dict: Dictionary that contains the output paths with .tsv formats. Note that the keys correspond to
    the keys of the dataframe_dict.
    :param html_out_dict: Dictionary that contains the output paths with .html formats. Note that the keys correspond to
    the keys of the dataframe_dict.
    """
    for key in dataframe_dict:
        dataframe, title = format_text(dataframe_dict[key], key)
        with open(tsv_out_dict[key], "w") as tsv:
            # noinspection PyTypeChecker
            dataframe.to_csv(tsv, sep="\t")

        formatted_df = format_df(dataframe, title)
        with open(html_out_dict[key], "w") as html:
            html.write(formatted_df.to_html())
        soup = deal_with_large_tables(html_out_dict[key])
        with open(html_out_dict[key], "w") as html:
            html.write(str(soup.prettify()))


def dictionaries_to_output_dataframe(dictionaries: Dict[str, DefaultDict[str, list]], output: Path,
                                     labels: Path) -> Dict[str, Path]:
    """
    Represent the dictionaries as dataframe and make a tsv and an html output for the dataframes. For the MFEprimer and
    amplicon results, nested dataframes will be generated.
    :param dictionaries: It contains a dictionary with results for every attribute (dataframe).
    Each nested dictionary will be a dataframe with each key representing a column.
    :param output: Relative path of output directory.
    :param labels: Path to the Labels.json file generated by mash_dendrogram.py giving annotations by the distances.
    :return: Dictionary with the .html paths for the main dataframes.
    """
    dataframe_dict = {}
    output = output / "html_sub"
    Path.mkdir(output, exist_ok=True)

    for key in dictionaries.keys():
        dataframe = pd.DataFrame.from_dict(dictionaries[key])
        dataframe = remove_duplicates(dataframe, key)
        if key == "general_results" and not dataframe.dtypes["t3sepp_prediction_score"] == float:
            dataframe = dataframe.loc[:, dataframe.columns != "t3sepp_prediction_score"]
        elif key == "genome_names":
            # Save a genomes name table without hyperlinks.
            dataframe = reformat_genome_names_df(dataframe, labels)
        elif key == "mfe_primer":
            dataframe.drop(columns=["control_specific_ingroup", "control_specific_outgroup"], inplace=True)
        elif key == "amplicons":
            # Save a non-nested amplicon table.
            with open(output / "Amplicons_raw_dataframe.tsv", "w") as tsv:
                # noinspection PyTypeChecker
                dataframe.to_csv(tsv, sep="\t")
                dataframe = dataframe[[column.strip("\n") for column in list(dataframe.columns)
                                       if not column.endswith("extended")]]

        dataframe_dict[key] = dataframe

    dataframe_dict["mfe_primer"], nested_mfe_dataframes_ingroup, output_mfe_tsv_ingroup, output_mfe_html_ingroup = \
        make_nested_dataframes(dataframe_dict["mfe_primer"], dataframe_dict["genome_names"]["ingroup_genomes_raw"],
                                   "ingroup", "mfeprimer", output)
    dataframe_dict["mfe_primer"], nested_mfe_dataframes_outgroup, output_mfe_tsv_outgroup, output_mfe_html_outgroup = \
        make_nested_dataframes(dataframe_dict["mfe_primer"], dataframe_dict["genome_names"]["outgroup_genomes_raw"],
                                   "outgroup", "mfeprimer", output)
    dataframe_dict["amplicons"], nested_amplicon_dataframes_ingroup, output_amplicon_tsv_ingroup, \
    output_amplicon_html_ingroup = make_nested_dataframes(dataframe_dict["amplicons"],
                                                          dataframe_dict["genome_names"]["ingroup_genomes_raw"],
                                                          "ingroup", "amplicon", output)
    dataframe_dict["amplicons"], nested_amplicon_dataframes_outgroup, output_amplicon_tsv_outgroup, \
    output_amplicon_html_outgroup = make_nested_dataframes(dataframe_dict["amplicons"],
                                                           dataframe_dict["genome_names"]["outgroup_genomes_raw"],
                                                           "outgroup", "amplicon", output)

    output_path_html_files = write_main_dataframes_to_output_files(dataframe_dict, output)
    write_nested_dataframes_to_output(nested_mfe_dataframes_ingroup, output_mfe_tsv_ingroup, output_mfe_html_ingroup)
    write_nested_dataframes_to_output(nested_mfe_dataframes_outgroup, output_mfe_tsv_outgroup, output_mfe_html_outgroup)
    write_nested_dataframes_to_output(nested_amplicon_dataframes_ingroup, output_amplicon_tsv_ingroup,
                                      output_amplicon_html_ingroup)
    write_nested_dataframes_to_output(nested_amplicon_dataframes_outgroup, output_amplicon_tsv_outgroup,
                                      output_amplicon_html_outgroup)

    return output_path_html_files


def style_html_tables(output: Path):
    """
    Function that takes the generated .html tables and adds a dynamic function in JavaScript for table sorting.
    An additional styling is added for the table sorting.
    :param output: Relative path of output directory.
    """
    with open("./src/css/tables.css") as f:
        css = f.read()
    with open("./src/js/table_sort.js") as f:
        javascript = f.read()

    html_tables = list(Path(output).glob("*" + HTML_EXTENSION))
    for html_table in html_tables:
        soup = deal_with_large_tables(html_table)

        # Add head tag
        head_tag = soup.new_tag("head")
        # Add css styling for the table sorting to the style tag.
        style_tag = soup.find("style")
        style_tag.append(css)
        contents = style_tag.replace_with(head_tag)
        head_tag.append(contents)
        # Add an icon.
        head_tag.append(BeautifulSoup('<meta charset="UTF-8">', "html.parser"))
        head_tag.append(BeautifulSoup('<link rel="shortcut icon" type="image/x-icon" href="img/nak_logo_small.png">',
                                      "html.parser"))

        # Make a div from the table.
        div_tag = soup.new_tag("div")
        div_tag["class"] = "table"
        table_tag = soup.find("table")
        contents = table_tag.replace_with(div_tag)
        div_tag.append(contents)

        # Add a class to the table tag.
        table_tag["class"] = "table-sortable"

        # Add Naktuinbouw logo to the file.
        div_nak_logo = '<div id="nak_logo" class="nak_logo"> ' \
                       '<img src="img/nak_logo.png" width="376" height="113.33" alt="Naktuinbouw logo"> </div>'
        div_tag.append(BeautifulSoup(div_nak_logo, "html.parser"))

        # Add credit to the file.
        div_credit = '<div id="credit" class="credit"> <p>Dijkstra T. R. J. BSc. (2022)</p> </div>'
        div_tag.append(BeautifulSoup(div_credit, "html.parser"))

        # Add JavaScript to the file.
        new_script_tag = soup.new_tag("script")
        soup.append(new_script_tag)
        script_tag = soup.find("script")
        script_tag.append(javascript)

        with open(html_table, "w") as html:
            html.write(str(soup.prettify()))
        print(f"{Fore.BLUE}Finished formatting table {html_table.stem}")


def main_menu_hyperlinks(output_path_html_files: Dict[str, Path]) -> Tuple[str, str, str, str, str, str]:
    """
    Format five hyperlinks that redirects the user from the main menu to a new window with data.
    :param output_path_html_files: Dictionary with the .html paths for the main dataframes.
    :return: Tuple with five strings.
    """
    hyperlinks = []
    for key in output_path_html_files:
        if key != "mfe_primer":
            hyperlink_text = key[0].upper() + key[1:].replace("_", " ")
        else:
            hyperlink_text = key[0:3].upper() + key[3:].replace("_", "")
        hyperlinks.append(F'<p><a href="{output_path_html_files[key]}">{hyperlink_text}</font></a></p>')
    amplicons, general_results, genome_names, mfe_primer, multiplex, primer3 = hyperlinks[0], hyperlinks[1], \
                                                                               hyperlinks[2], hyperlinks[3], \
                                                                               hyperlinks[4], hyperlinks[5]
    return amplicons, general_results, genome_names, mfe_primer, multiplex, primer3


def main_menu(output: Path, output_path_html_files: Dict[str, Path]):
    """
    Function that styles the main menu of the output.
    :param output: Relative path of output directory.
    :param output_path_html_files: Dictionary with the .html paths for the main dataframes.
    """
    output_menu = Path(output / "Main_menu").with_suffix(".html")
    output_path_html_files["multiplex_assays"] = output / "html_sub" / "Effector_primers_multiplex.html"
    amplicons, general_results, genome_names, mfe_primer, multiplex, primer3 = \
        main_menu_hyperlinks(output_path_html_files)

    with open("./src/css/main_menu.css") as f:
        css = f.read()

    with open("./src/html/Main_menu_template.html") as f:
        soup = BeautifulSoup(f, "html.parser")

    # Add css styling for the table sorting to the style tag.
    style_tag = soup.find("style")
    style_tag.append(css)

    # Add hyperlinks to the body.
    body_tag = soup.find("body")
    body_tag.append(BeautifulSoup(general_results, "html.parser"))
    body_tag.append(BeautifulSoup('<p><a href="html_sub/img/Mash_tree_ete3.png" target="_blank">Mash dendrogram</a></p>',
                                  "html.parser"))
    body_tag.append(BeautifulSoup(primer3, "html.parser"))
    body_tag.append(BeautifulSoup(mfe_primer, "html.parser"))
    body_tag.append(BeautifulSoup(multiplex, "html.parser"))
    body_tag.append(BeautifulSoup(amplicons, "html.parser"))
    body_tag.append(BeautifulSoup(genome_names, "html.parser"))

    with open(output_menu, "w") as html:
        html.write(str(soup.prettify()))
    print(f"{Fore.BLUE}Finished formatting Main menu.")


def main():
    args = parse_args()
    directory_exists(args.output)
    primer3_dataframe = generate_primer3_dataframe(args.primer3)
    mfe_dataframe = generate_mfe_dataframes(args.mfe_ingroup, args.mfe_outgroup)
    if args.t3sepp:
        t3sepp_dataframe = make_dataframe_effectors(Path(args.t3sepp))
        master_dataframe = combine_dataframes(primer3_dataframe, mfe_dataframe, t3sepp_dataframe)
    else:
        master_dataframe = combine_dataframes(primer3_dataframe, mfe_dataframe)
    combined_results, attributes = initialize_classes(master_dataframe)
    merged_dictionaries = merge_dictionaries(combined_results, attributes)
    output_path_html_files = dictionaries_to_output_dataframe(merged_dictionaries, args.output, args.labels)
    labels_json = f"--labels {args.labels}" if args.labels.is_file() else ""
    subprocess.run(f"python3 {args.multiplex_script} --input_dir {args.output / 'html_sub'} {labels_json} "
                   f"--output {args.output / 'html_sub'}", shell=True)
    style_html_tables(args.output / "html_sub")
    main_menu(args.output, output_path_html_files)

    print(F"{Fore.GREEN}FINISHED")


if __name__ == '__main__':
    main()
